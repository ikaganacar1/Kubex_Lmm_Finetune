import os
import json
import time
import requests
import re


# Ollama server configuration
ollama_server = "http://10.150.96.44:11434"
model_name = "qwen3-coder:30b"  # Updated model name

output_file = 'SimpleSingleStepOperations.jsonl'
num_examples_to_generate = 8000 # Set the total number of examples you want
examples_per_batch = 5  # Generate 5 examples per API call

prompt = """Elbette, bir √∂nceki prompt'u g√ºncelleyerek verdiƒüiniz t√ºm endpoint listesini, yapay zekanƒ±n ba≈üvuracaƒüƒ± temel kaynak olarak ekliyorum. Bu sayede, AI'nƒ±n sadece ge√ßerli `operationId`'leri kullanmasƒ± ve bu listeden √ße≈üitli se√ßimler yapmasƒ± saƒülanacaktƒ±r.

ƒ∞≈üte en g√ºncel ve kapsamlƒ± prompt versiyonu:

-----

### **Yeniden D√ºzenlenmi≈ü ve Geli≈ütirilmi≈ü Prompt (v3)**

**Hedef:** KubeX Kubernetes operasyonlarƒ± i√ßin **5 adet**, birbirinden tamamen **farklƒ±, yaratƒ±cƒ± ve T√ºrk√ße** √ßok a≈üamalƒ± eƒüitim verisi olu≈ütur.

**EN √ñNEMLƒ∞ KURALLAR:**

1.  **Tamamen T√ºrk√ße ƒ∞√ßerik:** √úretilecek t√ºm i√ßerik (`user` mesajƒ±, `assistant` mesajlarƒ±, `tool` cevabƒ±ndan √ºretilen √∂zet) istisnasƒ±z olarak **tamamen T√ºrk√ße** olmalƒ±dƒ±r. Dil kullanƒ±mƒ± doƒüal ve akƒ±cƒ± olsun.
2.  **Maksimum √áe≈üitlilik:** Her bir √∂rnek hem senaryo hem de kullanƒ±lan dil a√ßƒ±sƒ±ndan bir diƒüerinden belirgin ≈üekilde farklƒ± olmalƒ±dƒ±r. A≈üaƒüƒ±daki √ße≈üitlilik kurallarƒ±na ve saƒülanan API listesine mutlaka uy.
3.  **Kesin JSON Formatƒ±:** Yanƒ±tƒ±n **sadece 5 adet** JSON nesnesi i√ßermelidir. Her JSON nesnesi ayrƒ± bir satƒ±rda olmalƒ±, markdown veya kod bloƒüu i√ßinde olmamalƒ±dƒ±r.

**√áƒ±ktƒ± Formatƒ±:**

```
{"messages": [...]}
{"messages": [...]}
{"messages": [...]}
{"messages": [...]}
{"messages": [...]}
```

-----

### **JSON Yapƒ±sƒ± ve ƒ∞√ßerik Gereksinimleri:**

1.  **Anahtar:** Her JSON nesnesi sadece `"messages"` anahtarƒ±na sahip olmalƒ±dƒ±r.
2.  **Rol Sƒ±ralamasƒ±:** `"messages"` dizisi ≈üu 5 rol√º tam olarak bu sƒ±rayla i√ßermelidir: `system`, `user`, `assistant`, `tool`, `assistant`.
3.  **Rol ƒ∞√ßerikleri:**
      * `system`: Bu mesaj sabit kalacak: "Sen KubeX Kubernetes y√∂netim asistanƒ±sƒ±n. KubeX API'sini kullanarak cluster, deployment, pod, sanal makine ve diƒüer Kubernetes kaynaklarƒ±nƒ± y√∂netebilirsin. Sadece sana sunulan KubeX API ara√ßlarƒ±nƒ± kullan. Kubernetes y√∂netimi dƒ±≈üƒ±ndaki konularda sorulan sorularƒ± kibarca reddet."
      * `user`: **Yaratƒ±cƒ± ve √ße≈üitli** kullanƒ±cƒ± istekleri olu≈ütur. (Ayrƒ±ntƒ±lar a≈üaƒüƒ±da)
      * `assistant` (ilk cevap): Kullanƒ±cƒ±nƒ±n isteƒüini anladƒ±ƒüƒ±nƒ± belirten kƒ±sa, doƒüal bir T√ºrk√ße c√ºmle kur ve **TEK Bƒ∞R** KubeX API ara√ß √ßaƒürƒ±sƒ± yap. Ara√ß √ßaƒürƒ±sƒ± yaparken a≈üaƒüƒ±daki listede verilen ge√ßerli `operationId`'lerden birini kullan.
      * `tool`: KubeX API'sinden d√∂nen ger√ßek√ßi bir JSON yanƒ±tƒ±nƒ± string formatƒ±nda sun. **Veriler √ße≈üitli ve ger√ßek√ßi olsun** (√∂rneƒüin, her ≈üey "Ready" veya "Running" olmak zorunda deƒüil).
      * `assistant` (son cevap): `tool` i√ßeriƒüini baz alarak kullanƒ±cƒ±ya **anla≈üƒ±lƒ±r, iyi formatlanmƒ±≈ü (Markdown kullanarak) ve tamamen T√ºrk√ße** bir √∂zet sun.

-----

### **√áe≈üitlilik ve Yaratƒ±cƒ±lƒ±k Kurallarƒ±:**

  * **Farklƒ± Kullanƒ±cƒ± Profilleri Olu≈ütur:** Acemi kullanƒ±cƒ± ("Pod'larƒ± g√∂ster"), deneyimli m√ºhendis ("staging-cluster'daki 'monitoring' namespace'i i√ßin pod √∂zetini getir") veya aceleci y√∂netici ("Prod cluster √∂zeti l√ºtfen") gibi farklƒ± profillerde sorular olu≈ütur.
  * **Farklƒ± Senaryolar Kurgula:** Sadece listeleme yapma. Bir **saƒülƒ±k kontrol√º**, bir kaynaƒüƒ±n **detaylƒ± bilgisi**, bir **√∂l√ßekleme** (`scale`) i≈ülemi, bir **log** (`logs`) sorgusu veya bir **sanal makine ba≈ülatma** (`start`) gibi farklƒ± API komutlarƒ±nƒ± her √∂rnekte deƒüi≈ütirerek kullan.
  * **Ger√ßek√ßi API Yanƒ±tlarƒ± Sim√ºle Et:** `tool` rol√ºn√ºn i√ßeriƒüini √ße≈üitlendir. Bir node `Ready` iken diƒüeri `NotReady` olabilir. Bir pod `Running` iken ba≈ükasƒ± `Pending` veya `CrashLoopBackOff` durumunda olabilir.

-----

### **Kullanƒ±labilecek API Operasyonlarƒ± (`operationId` listesi):**

A≈üaƒüƒ±daki listeden her √∂rnek i√ßin **farklƒ± bir tane** `operationId` se√ßmeye √∂zen g√∂ster. Bu liste, kullanabileceƒüin ge√ßerli ara√ßlarƒ± tanƒ±mlar.

  * **Cluster Y√∂netimi:** `cluster_index`, `cluster_create`, `cluster_update`, `cluster_summary`, `cluster_toggle_favorite`, `cluster_health`
  * **Kubeconfig Y√∂netimi:** `kubeconfig_index`, `kubeconfig_create`
  * **ƒ∞≈ü (Job) Y√∂netimi:** `job_index`, `job_create`, `job_run`
  * **Namespace Y√∂netimi:** `namespace_show`, `namespace_pod_summary`, `namespace_index`
  * **Node Y√∂netimi:** `node_show`, `node_index`
  * **Deployment Y√∂netimi:** `deployment_index`, `deployment_show`, `deployment_scale`, `deployment_redeploy`, `deployment_get_detailed_config`, `deployment_update_container_image`, `deployment_update_image_pull_secret`, `deployment_update_environment`, `deployment_update_labels`, `deployment_get_pods_by_deployment_id_real_time`
  * **Service Y√∂netimi:** `service_index`, `service_show`, `service_index_port_forwarding_list`, `service_start_port_forward`, `service_delete_port_forward`
  * **ƒ∞zleme ve Uyarƒ±lar:** `prometheus_proxy`, `alert_get`
  * **Pod Y√∂netimi:** `pod_index`, `pod_logs`
  * **Depolama (Storage) Y√∂netimi:** `pvc_index`, `pvc_delete`, `storage_class_index`
  * **Sanal Makine (VM) Y√∂netimi:** `virtual_machine_index`, `virtual_machine_instances`, `virtual_machine_sets`, `virtual_machine_start`, `virtual_machine_stop`, `virtual_machine_create`, `virtual_machine_vnc`, `virtual_machine_stop_vnc`, `virtual_machine_instant_screenshot`, `virtual_machine_vnc_keepalive`
  * **Veri ve ƒ∞maj Y√∂netimi (VM):** `data_volume_index_all_namespaces`, `data_volume_index_single_namespace`, `data_volume_create`, `data_volume_delete`, `data_volume_create_blank`, `image_index_all_namespaces`, `image_index_single_namespace`
  * **ISO Y√∂netimi:** `iso_index`, `iso_create`, `iso_show`, `iso_delete`, `iso_update`, `iso_upload_image`, `iso_set_image_pvc`
  * **Helm & Repository Y√∂netimi:** `repository_index`, `repository_add`, `repository_delete`, `repository_update`, `repository_health_of_helm`, `repository_install`
  * **Uygulama ve Aƒü Y√∂netimi:** `installed_app_index`, `network_index`
  * **Diƒüer Ara√ßlar:** `visionary_run`

-----

### **√ñrnek (Sadece Yapƒ±yƒ± G√∂sterir, ƒ∞√ßeriƒüi Kopyalama\!):**

Bu √∂rnek sadece uyman gereken **yapƒ±yƒ±** g√∂stermektedir. ƒ∞√ßeriƒüi, senaryoyu ve dili birebir kopyalama. Kendi yaratƒ±cƒ± ve √ße≈üitli 5 √∂rneƒüini bu yapƒ±ya g√∂re olu≈ütur.

````json
{"messages": [{"role": "system", "content": "Sen KubeX Kubernetes y√∂netim asistanƒ±sƒ±n. KubeX API'sini kullanarak cluster, deployment, pod, sanal makine ve diƒüer Kubernetes kaynaklarƒ±nƒ± y√∂netebilirsin. Sadece sana sunulan KubeX API ara√ßlarƒ±nƒ± kullan. Kubernetes y√∂netimi dƒ±≈üƒ±ndaki konularda sorulan sorularƒ± kibarca reddet."}, {"role": "user", "content": "Staging cluster'daki `api-gateway-7b...` podunun loglarƒ±na bakmam lazƒ±m, bir hata var sanƒ±rƒ±m."}, {"role": "assistant", "content": "Hemen `api-gateway-7b...` podunun loglarƒ±nƒ± getiriyorum.", "tool_calls": [{"type": "function", "function": {"name": "pod_logs", "arguments": "{\"cluster_id\": \"staging-k8s\", \"namespace\": \"default\", \"pod_name\": \"api-gateway-7b...\"}"}}]}, {"role": "tool", "content": "{\"logs\": \"time=\\\"2023-10-27T10:30:00Z\\\" level=info msg=\\\"Starting server on port 8080\\\"\\ntime=\\\"2023-10-27T10:31:15Z\\\" level=error msg=\\\"Failed to connect to upstream service: redis-service.default.svc.cluster.local\\\"\\ntime=\\\"2023-10-27T10:31:15Z\\\" level=fatal msg=\\\"Upstream connection error, shutting down...\\\"\"}"}, {"role": "assistant", "content": "ƒ∞stediƒüiniz pod'un loglarƒ± a≈üaƒüƒ±da belirtilmi≈ütir:\n\n### `api-gateway-7b...` Pod Loglarƒ±\n\n```\ntime=\"2023-10-27T10:30:00Z\" level=info msg=\"Starting server on port 8080\"\ntime=\"2023-10-27T10:31:15Z\" level=error msg=\"Failed to connect to upstream service: redis-service.default.svc.cluster.local\"\ntime=\"2023-10-27T10:31:15Z\" level=fatal msg=\"Upstream connection error, shutting down...\"\n```\n\nG√∂r√ºn√º≈üe g√∂re pod, `redis-service` isimli servise baƒülanamadƒ±ƒüƒ± i√ßin kritik bir hata alƒ±p kapanƒ±yor."}]}
````

**≈ûimdi, yukarƒ±daki t√ºm kurallara ve √ße≈üitlilik prensiplerine uyarak 5 yeni ve √∂zg√ºn √∂rnek olu≈ütur.**"""

def call_ollama_api(prompt, max_retries=3, timeout=120):
    """
    Make an API call to Ollama server with retry logic
    Increased timeout for generating 5 examples
    """
    url = f"{ollama_server}/api/generate"
    
    payload = {
        "model": model_name,
        "prompt": prompt,
        "stream": False
    }
    
    for attempt in range(max_retries):
        try:
            print(f"  -> Making API call to Ollama server (attempt {attempt + 1}/{max_retries})...")
            
            response = requests.post(
                url, 
                json=payload, 
                timeout=timeout,
                headers={'Content-Type': 'application/json'}
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            else:
                print(f"  -> ‚ö†Ô∏è API call failed with status {response.status_code}: {response.text}")
                
        except requests.exceptions.Timeout:
            print(f"  -> ‚ö†Ô∏è Request timed out (attempt {attempt + 1}/{max_retries})")
            
        except requests.exceptions.ConnectionError:
            print(f"  -> ‚ö†Ô∏è Connection error (attempt {attempt + 1}/{max_retries})")
            
        except Exception as e:
            print(f"  -> ‚ö†Ô∏è Unexpected error: {e} (attempt {attempt + 1}/{max_retries})")
        
        if attempt < max_retries - 1:
            wait_time = 2 ** attempt  # Exponential backoff
            print(f"  -> Waiting {wait_time} seconds before retry...")
            time.sleep(wait_time)
    
    raise Exception(f"Failed to get response from Ollama after {max_retries} attempts")

def parse_multiple_json_objects(response_text):
    """
    Parse multiple JSON objects from the response text.
    Returns a list of valid JSON objects.
    """
    # Clean up the response
    clean_text = response_text.strip()
    
    # Remove markdown code blocks if present
    clean_text = re.sub(r'^```(?:json)?\s*\n?', '', clean_text, flags=re.MULTILINE)
    clean_text = re.sub(r'\n?```\s*$', '', clean_text, flags=re.MULTILINE)
    
    # Split by lines and try to parse each line as JSON
    lines = clean_text.split('\n')
    json_objects = []
    current_json = ""
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # If line starts with {, it might be a new JSON object
        if line.startswith('{'):
            # If we have accumulated JSON, try to parse it first
            if current_json:
                try:
                    data = json.loads(current_json)
                    if 'messages' in data:
                        json_objects.append(data)
                except json.JSONDecodeError:
                    pass
            current_json = line
        else:
            # Continue building the current JSON object
            current_json += " " + line if current_json else line
    
    # Don't forget the last JSON object
    if current_json:
        try:
            data = json.loads(current_json)
            if 'messages' in data:
                json_objects.append(data)
        except json.JSONDecodeError:
            pass
    
    # Alternative approach: try to find JSON objects using regex
    if len(json_objects) < examples_per_batch:
        # Look for complete JSON objects in the text
        json_pattern = r'\{"messages":\s*\[.*?\]\}'
        matches = re.findall(json_pattern, clean_text, re.DOTALL)
        
        for match in matches:
            try:
                data = json.loads(match)
                if data not in json_objects:  # Avoid duplicates
                    json_objects.append(data)
            except json.JSONDecodeError:
                continue
    
    return json_objects

def test_ollama_connection():
    """
    Test connection to Ollama server
    """
    try:
        print("Testing connection to Ollama server...")
        url = f"{ollama_server}/api/tags"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            models = response.json()
            print(f"‚úÖ Connection successful! Available models: {[m['name'] for m in models.get('models', [])]}")
            
            # Check if our target model is available
            model_names = [m['name'] for m in models.get('models', [])]
            if model_name not in model_names:
                print(f"‚ö†Ô∏è WARNING: Model '{model_name}' not found in available models.")
                print(f"Available models: {model_names}")
                
            return True
        else:
            print(f"‚ùå Connection failed with status {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Connection test failed: {e}")
        return False

def generate_data():
    """
    Main function to generate synthetic data and write it to a file.
    Now generates 5 examples per API call.
    """
    # Test connection first
    if not test_ollama_connection():
        print("üõë HATA: Ollama sunucusuna baƒülanƒ±lamƒ±yor. Sunucu URL'sini kontrol edin ve tekrar deneyin.")
        return

    # Calculate how many batches we need
    total_batches = (num_examples_to_generate + examples_per_batch - 1) // examples_per_batch
    print(f"Starting generation of {num_examples_to_generate} examples in {total_batches} batches of {examples_per_batch} examples each...")
    print(f"Output file: '{output_file}'")

    examples_generated = 0
    
    # Open the file in append mode ('a') to add new lines without deleting existing ones
    with open(output_file, 'a', encoding='utf-8') as f:
        for batch_num in range(total_batches):
            try:
                remaining_examples = min(examples_per_batch, num_examples_to_generate - examples_generated)
                print(f"\nGenerating batch {batch_num + 1}/{total_batches} ({remaining_examples} examples)...")
                
                # Make the API call with retry logic
                response_text = call_ollama_api(prompt)
                
                # Parse multiple JSON objects from the response
                json_objects = parse_multiple_json_objects(response_text)
                
                if not json_objects:
                    print(f"  -> ‚ö†Ô∏è WARNING: No valid JSON objects found in batch {batch_num + 1}. Skipping.")
                    continue
                
                # Write each valid JSON object to the file
                successful_writes = 0
                for i, data in enumerate(json_objects[:remaining_examples]):  # Limit to remaining examples needed
                    try:
                        # Validate the structure
                        if 'messages' not in data:
                            print(f"  -> ‚ö†Ô∏è WARNING: JSON object {i+1} missing 'messages' key. Skipping.")
                            continue
                        
                        # Convert to compact JSON string (one line)
                        json_line = json.dumps(data, ensure_ascii=False)
                        
                        # Write the single-line JSON to the file
                        f.write(json_line + '\n')
                        successful_writes += 1
                        examples_generated += 1
                        
                    except Exception as e:
                        print(f"  -> ‚ö†Ô∏è WARNING: Error processing JSON object {i+1}: {e}")
                
                f.flush()  # Ensure data is written to disk immediately
                
                print(f"  -> ‚úÖ Successfully wrote {successful_writes}/{len(json_objects)} examples from batch {batch_num + 1}")
                
                # Check if we've generated enough examples
                if examples_generated >= num_examples_to_generate:
                    break
                
            except Exception as e:
                print(f"  -> üõë An unexpected error occurred in batch {batch_num + 1}: {e}. Skipping batch.")
                
            # Small delay to avoid overwhelming the server
            time.sleep(0.2)

    print(f"\n‚úÖ Generation complete. Generated {examples_generated} examples and saved to '{output_file}'.")

if __name__ == "__main__":
    generate_data()