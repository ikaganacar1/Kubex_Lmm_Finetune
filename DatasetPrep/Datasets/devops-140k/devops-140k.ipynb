{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d5ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/ahmedgongi/Devops_LLM/Devops_Stackoverflow.json\")\n",
    "df.to_json(\"devops-140k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ba416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to package a docker image in a single file\n",
      "\n",
      "I have a 5GB docker image named \"ubuntu-dev-update-15\", which I developed on my local Ubuntu 14 dev machine.\n",
      "In that image I have everything I need to do my development work.\n",
      "Now I need to be able to send this image to a different linux host.\n",
      "What is the procedure for doing that?\n",
      "\n",
      "get an account on docker hub.https://hub.docker.com/account/signup/once signed up (only do that once), you log in from the host that has the image you want to push:docker login\n",
      "    (login with your username, password, and email address)then you push your image up there.  you probably will need to tag it first. say you created a new account called mynewacc, first, you tag your image:docker tag ubuntu-dev-update-15 mynewacc/ubuntu-dev-update-15then push the image up to your docker hub:docker push mynewacc/ubuntu-dev-update-15now anybody else with docker can pull your image down:docker pull mynewacc/ubuntu-dev-update-15then to run the image:docker run -it mynewacc/ubuntu-dev-update-15 /bin/bashyou can skip the pull step, if the image doesn't exist it will be pulled anyway.  the pull guarantees you get the freshest one.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('devops-140k.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data.get(\"Prompt\").get(\"1\"))\n",
    "print()\n",
    "print(data.get(\"Instruction\").get(\"1\"))\n",
    "print()\n",
    "print(data.get(\"Response\").get(\"1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f120a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_chatml(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Convert DevOps dataset to ChatML format\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input JSON file\n",
    "        output_file (str): Path to output JSON file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the original dataset\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Get the number of entries (assuming all keys have the same number of entries)\n",
    "    num_entries = len(data.get(\"Prompt\", {}))\n",
    "    \n",
    "    chatml_conversations = []\n",
    "    \n",
    "    # Convert each entry to ChatML format\n",
    "    for i in range(1, num_entries + 1):  # Keys appear to be 1-indexed strings\n",
    "        key = str(i)\n",
    "        \n",
    "        # Extract data for this entry\n",
    "        prompt = data.get(\"Prompt\", {}).get(key, \"\")\n",
    "        instruction = data.get(\"Instruction\", {}).get(key, \"\")\n",
    "        response = data.get(\"Response\", {}).get(key, \"\")\n",
    "        \n",
    "        # Skip empty entries\n",
    "        if not prompt and not instruction and not response:\n",
    "            continue\n",
    "        \n",
    "        # Create ChatML conversation\n",
    "        conversation = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{prompt}\\n\\n{instruction}\".strip()\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": response.strip()\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        chatml_conversations.append(conversation)\n",
    "    \n",
    "    # Save to output file in JSONL format\n",
    "    with open(output_file, 'w') as file:\n",
    "        for conversation in chatml_conversations:\n",
    "            file.write(json.dumps(conversation) + '\\n')\n",
    "    \n",
    "    print(f\"Converted {len(chatml_conversations)} conversations to ChatML format\")\n",
    "    print(f\"Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91593688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 142730 conversations to ChatML format\n",
      "Output saved to: devops-140k-chatml.jsonl\n"
     ]
    }
   ],
   "source": [
    "convert_to_chatml('devops-140k.json', 'devops-140k-chatml.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
